{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from skbio.diversity import beta_diversity\n",
    "from skbio import TreeNode\n",
    "from ete3 import NCBITaxa\n",
    "from io import StringIO\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log, average, inf, nan, median, exp, interp, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLE_normalize(pd_dataframe):\n",
    "    '''\n",
    "    Normalize with Relative Log Expression\n",
    "    INPUT:\n",
    "        pd_dataframe(pandas DataFrame): Colums as Samples, Rows as OTUs\n",
    "    OUTPUT:\n",
    "        step7(pandas DataFrame): RLE Normalized. Colums as Samples, Rows as OTUs\n",
    "    '''\n",
    "    step1 = pd_dataframe.apply(log, 0)\n",
    "    step2 = step1.apply(average, 1)\n",
    "    step3 = step2[step2.replace([inf, -inf], nan).notnull()]\n",
    "    step4_1 = step1[step1.replace(\n",
    "        [inf, -inf], nan).notnull().all(axis=1)]\n",
    "    step4 = step4_1.subtract(step3, 0)\n",
    "    step5 = step4.apply(median, 0)\n",
    "    step6 = step5.apply(exp)\n",
    "    step7 = pd_dataframe.divide(step6, 1).apply(round, 1)\n",
    "    return(step7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sourcemap():\n",
    "    def __init__(self, train, test, labels, norm_method):\n",
    "        '''\n",
    "        train(pandas DataFrame) source otu table\n",
    "        test(pandas DataFrame) sink otu table\n",
    "        labels(list) train sample class\n",
    "        norm_method(str) normalization method\n",
    "        '''\n",
    "        self.train = pd.read_csv(train, index_col=0)\n",
    "        self.test = pd.read_csv(test, index_col=0)\n",
    "        self.comb = self.train.merge(\n",
    "            self.test, how='outer', left_index=True, right_index=True).fillna(0)\n",
    "        if norm_method == 'RLE':\n",
    "            self.combined = RLE_normalize(self.comb).T\n",
    "        self.train_samples = list(self.train.columns)\n",
    "        self.test_samples = list(self.test.columns)\n",
    "        labels = pd.read_csv(labels, index_col=0)\n",
    "        self.labels = labels['labels']\n",
    "\n",
    "    def compute_distance(self, rank='species'):\n",
    "        # Getting a single Taxonomic rank\n",
    "        ncbi = NCBITaxa()\n",
    "        only_rank = []\n",
    "        for i in list(self.combined.columns):\n",
    "            try:\n",
    "                if ncbi.get_rank([i])[i] == rank:\n",
    "                    only_rank.append(i)\n",
    "            except KeyError:\n",
    "                continue\n",
    "        self.normalized_rank = self.combined.loc[:,only_rank]\n",
    "        tree = ncbi.get_topology(\n",
    "            list(self.normalized_rank.columns), intermediate_nodes=False)\n",
    "        newick = TreeNode.read(StringIO(tree.write()))\n",
    "        wu = beta_diversity(\"weighted_unifrac\", self.normalized_rank.as_matrix().astype(int), ids=list(\n",
    "            self.normalized_rank.index), otu_ids=[str(i) for i in list(self.normalized_rank.columns)], tree=newick)\n",
    "        self.wu = wu.to_data_frame()\n",
    "\n",
    "    def embed(self, umap_csv, n_comp=200):\n",
    "        my_umap = umap.UMAP(metric='precomputed',\n",
    "                            n_neighbors=30, min_dist=0.03, n_components=n_comp, n_epochs=500)\n",
    "        umap_embed_a = my_umap.fit(self.wu)\n",
    "        cols = [f\"PC{i}\" for i in range(1, n_comp+1)]\n",
    "        self.umap = pd.DataFrame(\n",
    "            umap_embed_a.embedding_, columns=cols, index=self.normalized_rank.index)\n",
    "\n",
    "        if umap_csv:\n",
    "            to_write = self.umap.copy(deep=True)\n",
    "            y = self.labels.copy(deep=True)\n",
    "            y = y.append(\n",
    "                pd.Series(data=['sink']*len(list(self.test.index)), index=self.test.index))\n",
    "            to_write['label'] = y\n",
    "            to_write['name'] = to_write.index\n",
    "            to_write.to_csv(umap_csv)\n",
    "\n",
    "        self.source = self.umap.drop(self.test_samples, axis=0)\n",
    "        self.source['label'] = self.labels\n",
    "        self.sink = self.umap.drop(self.train_samples, axis=0)\n",
    "\n",
    "    def knn_classification(self, kfold, threads, seed):\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "            self.source.drop('label', axis=1), self.source.loc[:, 'label'], test_size=0.2, random_state=seed)\n",
    "        knn = KNeighborsClassifier(n_jobs=threads)\n",
    "\n",
    "        param_knn_grid = {\n",
    "            'n_neighbors': [3, 5, 10, 15, 20],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "\n",
    "        CV_knn = GridSearchCV(\n",
    "            estimator=knn, param_grid=param_knn_grid, cv=kfold, n_jobs=threads)\n",
    "\n",
    "        print(\n",
    "            f\"\\tPerforming {kfold} fold cross validation on {threads} cores...\")\n",
    "        CV_knn.fit(train_features, train_labels)\n",
    "\n",
    "        knn1 = KNeighborsClassifier(\n",
    "            n_neighbors=CV_knn.best_params_['n_neighbors'], weights=CV_knn.best_params_['weights'], n_jobs=threads)\n",
    "\n",
    "        knn1.fit(train_features, train_labels)\n",
    "        y_pred = knn1.predict(test_features)\n",
    "        print(\"\\t-> Testing Accuracy:\", metrics.accuracy_score(\n",
    "            test_labels, y_pred))\n",
    "        self.sink_pred = knn1.predict_proba(self.sink)\n",
    "        print_class(samples =self.sink.index, classes=knn1.classes_, pred=self.sink_pred)\n",
    "        predictions = class2dict(\n",
    "            samples = self.sink.index, classes=knn1.classes_, pred=self.sink_pred)\n",
    "        return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class(samples, classes, pred):\n",
    "    print(\"\\t----------------------\")\n",
    "    for i in range(0, len(samples)):\n",
    "        sample = samples[i]\n",
    "        print(f\"\\t- Sample: {sample}\")\n",
    "        [print(f'\\t\\t {i}:{j}')\n",
    "         for i, j in zip(list(classes), list(pred[i, :]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class2dict(samples, classes, pred):\n",
    "    resdict = {}\n",
    "    for i in range(0, len(samples)):\n",
    "        sample = samples[i]\n",
    "        resdict[sample] = {c: float(p) for (c, p) in zip(\n",
    "            list(classes), list(pred[i, :]))}\n",
    "    return(resdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = sourcemap(train=mysource, test=mysink, labels = mylabels, norm_method = \"RLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects1/users/borry/15_miniconda3/envs/sourcepredict/lib/python3.6/site-packages/ipykernel_launcher.py:34: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "u.compute_distance(rank=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.embed(n_comp=2, umap_csv=\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPerforming 2 fold cross validation on 2 cores...\n",
      "\t-> Testing Accuracy: 0.9861111111111112\n",
      "\t----------------------\n",
      "\t- Sample: ERR1915662\n",
      "\t\t Canis_familiaris:1.0\n",
      "\t\t Industrialized_humans:0.0\n",
      "\t\t Non_industrialized_humans:0.0\n",
      "\t\t Sus_scrofa:0.0\n",
      "\t- Sample: ERR1915662_copy\n",
      "\t\t Canis_familiaris:1.0\n",
      "\t\t Industrialized_humans:0.0\n",
      "\t\t Non_industrialized_humans:0.0\n",
      "\t\t Sus_scrofa:0.0\n"
     ]
    }
   ],
   "source": [
    "predicted_source = u.knn_classification(\n",
    "        kfold=2, threads=2, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ERR1915662': {'Canis_familiaris': 1.0,\n",
       "  'Industrialized_humans': 0.0,\n",
       "  'Non_industrialized_humans': 0.0,\n",
       "  'Sus_scrofa': 0.0},\n",
       " 'ERR1915662_copy': {'Canis_familiaris': 1.0,\n",
       "  'Industrialized_humans': 0.0,\n",
       "  'Non_industrialized_humans': 0.0,\n",
       "  'Sus_scrofa': 0.0}}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_source"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
