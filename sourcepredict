#!/usr/bin/env python3

import argparse
from sourcepredictlib.forest import sourceforest
from sourcepredictlib import utils
import os
import pandas as pd
import warnings
from . import utils


def _get_args():
    '''This function parses and return arguments passed in'''
    parser = argparse.ArgumentParser(
        prog='SourcePredict v' + str(version),
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=f'''
==========================================================
SourcePredict v{version}
Coprolite source classification
Author: Maxime Borry
Contact: <borry[at]shh.mpg.de>
Homepage & Documentation: github.com/maxibor/sourcepredict
==========================================================
        ''')
    parser.add_argument('otu_table', help="path to otu table in csv format")
    parser.add_argument(
        '-a',
        dest="alpha",
        default=0.1,
        help="Proportion of sink sample in unknown. Default = 0.1")
    parser.add_argument(
        '-s',
        dest="sources",
        default=os.path.dirname(os.path.abspath(
            __file__))+'/data/sourcepredict_sources.csv',
        help="Path to source csv file. Default = data/modern_gut_microbiomes_sources.csv")
    parser.add_argument(
        '-l',
        dest="labels",
        default=os.path.dirname(os.path.abspath(
            __file__)) + '/data/sourcepredict_labels.csv',
        help="Path to labels csv file. Default = data/modern_gut_microbiomes_labels.csv")
    parser.add_argument(
        '-n',
        dest="normalization",
        default='RLE',
        help="Normalization method (RLE | CLR | Subsample). Default = RLE")
    parser.add_argument(
        '-o',
        dest="output",
        default=None,
        help="Output file basename. Default = <sample_basename>.sourcepredict.csv")
    parser.add_argument(
        '-se',
        dest="seed",
        default=42,
        help="Seed for random generator. Default = 42")
    parser.add_argument(
        '-k',
        dest="kfold",
        default=3,
        help="Number of fold for K-fold cross validation in feature selection and parameter optimization. Default = 3")
    parser.add_argument(
        '-t',
        dest="threads",
        default=2,
        help="Number of threads for parallel processing. Default = 2")

    args = parser.parse_args()

    sink = args.otu_table
    alpha = float(args.alpha)
    normalization = args.normalization
    sources = args.sources
    labels = args.labels
    seed = int(args.seed)
    output = args.output
    kfold = int(args.kfold)
    threads = int(args.threads)

    return(sink, alpha, normalization, sources, labels, seed, output, kfold, threads)


if __name__ == "__main__":
    version = "0.1.1"
    warnings.filterwarnings("ignore")
    SINK, ALPHA, NORMALIZATION, SOURCES, LABELS, SEED, OUTPUT, KFOLD, THREADS = _get_args()
    SEED = utils.check_gen_seed(SEED)
    NORMALIZATION = utils.check_norm(NORMALIZATION)
    sinks = utils.split_sinks(SINK)
    predictions = {}
    unifrac_rank = "species"
    for s in sinks:
        print(f"Sample: {''.join(list(s.columns))}")
        print("Step 1: Checking for unknown proportion")
        a = sourceforest(source=SOURCES, sink=s, labels=LABELS)
        print("Adding unknown")
        a.add_unknown(alpha=ALPHA)
        print("Normalizing")
        a.normalize(method=NORMALIZATION)
        print("Feature engineering")
        a.dim_reduction(20)
        # a.select_features(cv=KFOLD, quantile=0.20, threads=THREADS)
        print("Machine learning")
        predicted_unk = a.rndForest(seed=SEED, threads=THREADS, ratio=RATIO,
                                    outfile=OUTPUT, kfold=KFOLD)

        print("Step 2: Checking for sample proportion")
        print(f"Computing weighted unifrac distance on {unifrac_rank} rank")
        a.compute_distance(rank=unifrac_rank)
        a.embed(n_comp=2)
        predicted_source = a.knn_classification(
            kfold=KFOLD, threads=THREADS, seed=SEED)
        print("==============\n")

        prediction = utils.account_unk(predicted_unk, predicted_source)
        predictions["".join(list(s.columns))] = prediction
if OUTPUT is None:
    OUTPUT = f"{utils._get_basename(SINK)}.sourcepredict.csv"
pd.DataFrame(predictions).to_csv(OUTPUT)
